{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_encode_dataset(dataset):\n",
    "    for column in dataset.columns.values:\n",
    "        dataset[column] = dataset[column].astype(str)\n",
    "        le.fit(y=dataset[column])\n",
    "        dataset[column] = le.transform(dataset[column])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MatthewBarnette/shelter_animals/.direnv/python-3.5.0/lib/python3.5/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/Users/MatthewBarnette/shelter_animals/.direnv/python-3.5.0/lib/python3.5/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#import the data I need\n",
    "test_data = pd.read_csv('csv_files/test.csv')\n",
    "animal_data = pd.read_csv('csv_files/train.csv')\n",
    "\n",
    "#Drop columns that I don't need\n",
    "animal_data = animal_data.drop(labels=['AnimalID', 'Name', 'DateTime', 'OutcomeSubtype'], axis=1)\n",
    "\n",
    "#setting up the test data\n",
    "test_index = test_data.ID\n",
    "test_data = test_data.drop(labels=['ID', 'Name', 'DateTime'], axis=1)\n",
    "test_data = label_encode_dataset(test_data)\n",
    "\n",
    "#splitting up the training data so I can use it to test how well my predictions are coming along\n",
    "train_animal_data, test_animal_data = train_test_split(animal_data, test_size= .25, random_state=53)\n",
    "\n",
    "#since the evaluation for this kaggle competition will be in multi-class logloss I've popped the outcomes off of the\n",
    "#dataset and changed the results into dummy variables\n",
    "outcome_train_animal_data = train_animal_data.pop('OutcomeType')\n",
    "le.fit(outcome_train_animal_data)\n",
    "outcome_train_animal_data = le.transform(outcome_train_animal_data)\n",
    "\n",
    "#repeat for the test data\n",
    "outcome_test_animal_data = test_animal_data.pop('OutcomeType')\n",
    "le.fit(outcome_test_animal_data)\n",
    "outcome_test_animal_data = le.transform(outcome_test_animal_data)\n",
    "\n",
    "train_animal_data = label_encode_dataset(train_animal_data)\n",
    "test_animal_data = label_encode_dataset(test_animal_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(train_animal_data, label=outcome_train_animal_data)\n",
    "dtest = xgb.DMatrix(test_animal_data, label=outcome_test_animal_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parm = {'bst:max_depth':1, 'bst:eta':1, 'silent':1, 'objective':'multi:softprob', 'num_class':5, 'max_delta_step':1}\n",
    "parm['nthread'] = 1\n",
    "parm['eval_metric'] = 'mlogloss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evallist = [(dtrain,'train'), (dtest,'eval')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until eval error hasn't decreased in 3 rounds.\n",
      "[0]\ttrain-mlogloss:1.182768\teval-mlogloss:1.191795\n",
      "[1]\ttrain-mlogloss:1.073994\teval-mlogloss:1.086185\n",
      "[2]\ttrain-mlogloss:1.030188\teval-mlogloss:1.045041\n",
      "[3]\ttrain-mlogloss:1.008730\teval-mlogloss:1.026673\n",
      "[4]\ttrain-mlogloss:0.994793\teval-mlogloss:1.012845\n",
      "[5]\ttrain-mlogloss:0.985380\teval-mlogloss:1.005189\n",
      "[6]\ttrain-mlogloss:0.978674\teval-mlogloss:0.999544\n",
      "[7]\ttrain-mlogloss:0.972606\teval-mlogloss:0.993433\n",
      "[8]\ttrain-mlogloss:0.968068\teval-mlogloss:0.988502\n",
      "[9]\ttrain-mlogloss:0.964351\teval-mlogloss:0.984436\n",
      "[10]\ttrain-mlogloss:0.960964\teval-mlogloss:0.981067\n",
      "[11]\ttrain-mlogloss:0.957932\teval-mlogloss:0.979344\n",
      "[12]\ttrain-mlogloss:0.955571\teval-mlogloss:0.977957\n",
      "[13]\ttrain-mlogloss:0.953208\teval-mlogloss:0.977293\n",
      "[14]\ttrain-mlogloss:0.951341\teval-mlogloss:0.975390\n",
      "[15]\ttrain-mlogloss:0.949385\teval-mlogloss:0.973697\n",
      "[16]\ttrain-mlogloss:0.947218\teval-mlogloss:0.970894\n",
      "[17]\ttrain-mlogloss:0.945588\teval-mlogloss:0.969952\n",
      "[18]\ttrain-mlogloss:0.943995\teval-mlogloss:0.967762\n",
      "[19]\ttrain-mlogloss:0.942476\teval-mlogloss:0.966876\n",
      "[20]\ttrain-mlogloss:0.941127\teval-mlogloss:0.966137\n",
      "[21]\ttrain-mlogloss:0.940020\teval-mlogloss:0.965888\n",
      "[22]\ttrain-mlogloss:0.939014\teval-mlogloss:0.965385\n",
      "[23]\ttrain-mlogloss:0.937835\teval-mlogloss:0.965058\n",
      "[24]\ttrain-mlogloss:0.936780\teval-mlogloss:0.964710\n",
      "[25]\ttrain-mlogloss:0.935917\teval-mlogloss:0.964079\n",
      "[26]\ttrain-mlogloss:0.935074\teval-mlogloss:0.964578\n",
      "[27]\ttrain-mlogloss:0.934102\teval-mlogloss:0.963422\n",
      "[28]\ttrain-mlogloss:0.933116\teval-mlogloss:0.963072\n",
      "[29]\ttrain-mlogloss:0.932269\teval-mlogloss:0.964082\n",
      "[30]\ttrain-mlogloss:0.931528\teval-mlogloss:0.963961\n",
      "[31]\ttrain-mlogloss:0.930901\teval-mlogloss:0.963507\n",
      "Stopping. Best iteration:\n",
      "[28]\ttrain-mlogloss:0.933116\teval-mlogloss:0.963072\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_round = 100\n",
    "bst = xgb.train(parm, dtrain, num_round, evallist, early_stopping_rounds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MatthewBarnette/shelter_animals/.direnv/python-3.5.0/lib/python3.5/site-packages/xgboost/core.py:840: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  preds = preds.reshape(nrow, preds.size / nrow)\n"
     ]
    }
   ],
   "source": [
    "dtest = xgb.DMatrix(test_data)\n",
    "ypred = bst.predict(dtest, output_margin=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.046518</td>\n",
       "      <td>0.010577</td>\n",
       "      <td>0.076670</td>\n",
       "      <td>0.148234</td>\n",
       "      <td>0.718000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.526294</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.025972</td>\n",
       "      <td>0.235838</td>\n",
       "      <td>0.209295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.607212</td>\n",
       "      <td>0.007240</td>\n",
       "      <td>0.032945</td>\n",
       "      <td>0.057080</td>\n",
       "      <td>0.295523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.036110</td>\n",
       "      <td>0.011053</td>\n",
       "      <td>0.105230</td>\n",
       "      <td>0.240750</td>\n",
       "      <td>0.606858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.482738</td>\n",
       "      <td>0.001550</td>\n",
       "      <td>0.027143</td>\n",
       "      <td>0.280336</td>\n",
       "      <td>0.208234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.460087</td>\n",
       "      <td>0.002271</td>\n",
       "      <td>0.031072</td>\n",
       "      <td>0.290350</td>\n",
       "      <td>0.216220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.581632</td>\n",
       "      <td>0.007598</td>\n",
       "      <td>0.081169</td>\n",
       "      <td>0.108504</td>\n",
       "      <td>0.221097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.590968</td>\n",
       "      <td>0.007889</td>\n",
       "      <td>0.046457</td>\n",
       "      <td>0.087922</td>\n",
       "      <td>0.266763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.503792</td>\n",
       "      <td>0.001672</td>\n",
       "      <td>0.026269</td>\n",
       "      <td>0.264530</td>\n",
       "      <td>0.203738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.545966</td>\n",
       "      <td>0.001734</td>\n",
       "      <td>0.025998</td>\n",
       "      <td>0.244781</td>\n",
       "      <td>0.181521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.443309</td>\n",
       "      <td>0.002365</td>\n",
       "      <td>0.034850</td>\n",
       "      <td>0.315114</td>\n",
       "      <td>0.204361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.048982</td>\n",
       "      <td>0.009392</td>\n",
       "      <td>0.083663</td>\n",
       "      <td>0.201818</td>\n",
       "      <td>0.656145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.440856</td>\n",
       "      <td>0.001786</td>\n",
       "      <td>0.034657</td>\n",
       "      <td>0.356426</td>\n",
       "      <td>0.166275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.482738</td>\n",
       "      <td>0.001550</td>\n",
       "      <td>0.027143</td>\n",
       "      <td>0.280336</td>\n",
       "      <td>0.208234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.513305</td>\n",
       "      <td>0.002605</td>\n",
       "      <td>0.027850</td>\n",
       "      <td>0.230540</td>\n",
       "      <td>0.225700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.494129</td>\n",
       "      <td>0.001844</td>\n",
       "      <td>0.029289</td>\n",
       "      <td>0.280704</td>\n",
       "      <td>0.194034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.415845</td>\n",
       "      <td>0.002692</td>\n",
       "      <td>0.037247</td>\n",
       "      <td>0.336793</td>\n",
       "      <td>0.207423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.462907</td>\n",
       "      <td>0.002007</td>\n",
       "      <td>0.031263</td>\n",
       "      <td>0.263427</td>\n",
       "      <td>0.240396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.614966</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.036452</td>\n",
       "      <td>0.064287</td>\n",
       "      <td>0.277596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.043912</td>\n",
       "      <td>0.029350</td>\n",
       "      <td>0.090088</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.783838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.549870</td>\n",
       "      <td>0.005435</td>\n",
       "      <td>0.027135</td>\n",
       "      <td>0.051573</td>\n",
       "      <td>0.365988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.007408</td>\n",
       "      <td>0.017886</td>\n",
       "      <td>0.052300</td>\n",
       "      <td>0.014276</td>\n",
       "      <td>0.908130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.502389</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.027258</td>\n",
       "      <td>0.256639</td>\n",
       "      <td>0.212699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.052803</td>\n",
       "      <td>0.023999</td>\n",
       "      <td>0.087028</td>\n",
       "      <td>0.005293</td>\n",
       "      <td>0.830877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.547609</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>0.026077</td>\n",
       "      <td>0.239380</td>\n",
       "      <td>0.185481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.607212</td>\n",
       "      <td>0.007240</td>\n",
       "      <td>0.032945</td>\n",
       "      <td>0.057080</td>\n",
       "      <td>0.295523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.882248</td>\n",
       "      <td>0.002672</td>\n",
       "      <td>0.011781</td>\n",
       "      <td>0.018127</td>\n",
       "      <td>0.085172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.147936</td>\n",
       "      <td>0.012530</td>\n",
       "      <td>0.097120</td>\n",
       "      <td>0.220490</td>\n",
       "      <td>0.521924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.457713</td>\n",
       "      <td>0.003026</td>\n",
       "      <td>0.030912</td>\n",
       "      <td>0.260471</td>\n",
       "      <td>0.247877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.421771</td>\n",
       "      <td>0.002376</td>\n",
       "      <td>0.023715</td>\n",
       "      <td>0.215344</td>\n",
       "      <td>0.336794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11426</th>\n",
       "      <td>0.406091</td>\n",
       "      <td>0.001963</td>\n",
       "      <td>0.036373</td>\n",
       "      <td>0.364730</td>\n",
       "      <td>0.190844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11427</th>\n",
       "      <td>0.168902</td>\n",
       "      <td>0.010389</td>\n",
       "      <td>0.123212</td>\n",
       "      <td>0.148640</td>\n",
       "      <td>0.548857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11428</th>\n",
       "      <td>0.462325</td>\n",
       "      <td>0.001742</td>\n",
       "      <td>0.031224</td>\n",
       "      <td>0.299244</td>\n",
       "      <td>0.205465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11429</th>\n",
       "      <td>0.535222</td>\n",
       "      <td>0.002486</td>\n",
       "      <td>0.026412</td>\n",
       "      <td>0.239839</td>\n",
       "      <td>0.196041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11430</th>\n",
       "      <td>0.882248</td>\n",
       "      <td>0.002672</td>\n",
       "      <td>0.011781</td>\n",
       "      <td>0.018127</td>\n",
       "      <td>0.085172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11431</th>\n",
       "      <td>0.042880</td>\n",
       "      <td>0.039041</td>\n",
       "      <td>0.104032</td>\n",
       "      <td>0.053685</td>\n",
       "      <td>0.760362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11432</th>\n",
       "      <td>0.438017</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.034434</td>\n",
       "      <td>0.354131</td>\n",
       "      <td>0.172000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11433</th>\n",
       "      <td>0.178236</td>\n",
       "      <td>0.029349</td>\n",
       "      <td>0.082377</td>\n",
       "      <td>0.029604</td>\n",
       "      <td>0.680433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11434</th>\n",
       "      <td>0.443512</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.034866</td>\n",
       "      <td>0.349609</td>\n",
       "      <td>0.170413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11435</th>\n",
       "      <td>0.038282</td>\n",
       "      <td>0.040905</td>\n",
       "      <td>0.111561</td>\n",
       "      <td>0.053421</td>\n",
       "      <td>0.755830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11436</th>\n",
       "      <td>0.548208</td>\n",
       "      <td>0.007093</td>\n",
       "      <td>0.049103</td>\n",
       "      <td>0.092929</td>\n",
       "      <td>0.302667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11437</th>\n",
       "      <td>0.039347</td>\n",
       "      <td>0.005061</td>\n",
       "      <td>0.107058</td>\n",
       "      <td>0.226095</td>\n",
       "      <td>0.622439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11438</th>\n",
       "      <td>0.796977</td>\n",
       "      <td>0.004170</td>\n",
       "      <td>0.022986</td>\n",
       "      <td>0.028597</td>\n",
       "      <td>0.147270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11439</th>\n",
       "      <td>0.522322</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>0.025776</td>\n",
       "      <td>0.266217</td>\n",
       "      <td>0.184213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11440</th>\n",
       "      <td>0.013350</td>\n",
       "      <td>0.029081</td>\n",
       "      <td>0.075722</td>\n",
       "      <td>0.003052</td>\n",
       "      <td>0.878795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11441</th>\n",
       "      <td>0.407275</td>\n",
       "      <td>0.002168</td>\n",
       "      <td>0.027506</td>\n",
       "      <td>0.375173</td>\n",
       "      <td>0.187878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11442</th>\n",
       "      <td>0.501947</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.028223</td>\n",
       "      <td>0.256279</td>\n",
       "      <td>0.211864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11443</th>\n",
       "      <td>0.591907</td>\n",
       "      <td>0.006313</td>\n",
       "      <td>0.046531</td>\n",
       "      <td>0.088062</td>\n",
       "      <td>0.267187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11444</th>\n",
       "      <td>0.049677</td>\n",
       "      <td>0.031380</td>\n",
       "      <td>0.084849</td>\n",
       "      <td>0.037665</td>\n",
       "      <td>0.796429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11445</th>\n",
       "      <td>0.043054</td>\n",
       "      <td>0.031318</td>\n",
       "      <td>0.092231</td>\n",
       "      <td>0.038532</td>\n",
       "      <td>0.794865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11446</th>\n",
       "      <td>0.809111</td>\n",
       "      <td>0.002792</td>\n",
       "      <td>0.012310</td>\n",
       "      <td>0.018941</td>\n",
       "      <td>0.156845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11447</th>\n",
       "      <td>0.560589</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>0.026695</td>\n",
       "      <td>0.220976</td>\n",
       "      <td>0.189877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11448</th>\n",
       "      <td>0.827818</td>\n",
       "      <td>0.001475</td>\n",
       "      <td>0.011054</td>\n",
       "      <td>0.081263</td>\n",
       "      <td>0.078390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11449</th>\n",
       "      <td>0.443387</td>\n",
       "      <td>0.001881</td>\n",
       "      <td>0.034856</td>\n",
       "      <td>0.349511</td>\n",
       "      <td>0.170365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11450</th>\n",
       "      <td>0.510270</td>\n",
       "      <td>0.001475</td>\n",
       "      <td>0.027685</td>\n",
       "      <td>0.260665</td>\n",
       "      <td>0.199903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11451</th>\n",
       "      <td>0.809111</td>\n",
       "      <td>0.002792</td>\n",
       "      <td>0.012310</td>\n",
       "      <td>0.018941</td>\n",
       "      <td>0.156845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11452</th>\n",
       "      <td>0.050970</td>\n",
       "      <td>0.027387</td>\n",
       "      <td>0.076868</td>\n",
       "      <td>0.027624</td>\n",
       "      <td>0.817152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11453</th>\n",
       "      <td>0.050970</td>\n",
       "      <td>0.028996</td>\n",
       "      <td>0.084007</td>\n",
       "      <td>0.033995</td>\n",
       "      <td>0.802032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11454</th>\n",
       "      <td>0.415845</td>\n",
       "      <td>0.002692</td>\n",
       "      <td>0.037247</td>\n",
       "      <td>0.336793</td>\n",
       "      <td>0.207423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11455</th>\n",
       "      <td>0.029965</td>\n",
       "      <td>0.018077</td>\n",
       "      <td>0.087322</td>\n",
       "      <td>0.284326</td>\n",
       "      <td>0.580309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11456 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4\n",
       "0      0.046518  0.010577  0.076670  0.148234  0.718000\n",
       "1      0.526294  0.002603  0.025972  0.235838  0.209295\n",
       "2      0.607212  0.007240  0.032945  0.057080  0.295523\n",
       "3      0.036110  0.011053  0.105230  0.240750  0.606858\n",
       "4      0.482738  0.001550  0.027143  0.280336  0.208234\n",
       "5      0.460087  0.002271  0.031072  0.290350  0.216220\n",
       "6      0.581632  0.007598  0.081169  0.108504  0.221097\n",
       "7      0.590968  0.007889  0.046457  0.087922  0.266763\n",
       "8      0.503792  0.001672  0.026269  0.264530  0.203738\n",
       "9      0.545966  0.001734  0.025998  0.244781  0.181521\n",
       "10     0.443309  0.002365  0.034850  0.315114  0.204361\n",
       "11     0.048982  0.009392  0.083663  0.201818  0.656145\n",
       "12     0.440856  0.001786  0.034657  0.356426  0.166275\n",
       "13     0.482738  0.001550  0.027143  0.280336  0.208234\n",
       "14     0.513305  0.002605  0.027850  0.230540  0.225700\n",
       "15     0.494129  0.001844  0.029289  0.280704  0.194034\n",
       "16     0.415845  0.002692  0.037247  0.336793  0.207423\n",
       "17     0.462907  0.002007  0.031263  0.263427  0.240396\n",
       "18     0.614966  0.006700  0.036452  0.064287  0.277596\n",
       "19     0.043912  0.029350  0.090088  0.052813  0.783838\n",
       "20     0.549870  0.005435  0.027135  0.051573  0.365988\n",
       "21     0.007408  0.017886  0.052300  0.014276  0.908130\n",
       "22     0.502389  0.001014  0.027258  0.256639  0.212699\n",
       "23     0.052803  0.023999  0.087028  0.005293  0.830877\n",
       "24     0.547609  0.001455  0.026077  0.239380  0.185481\n",
       "25     0.607212  0.007240  0.032945  0.057080  0.295523\n",
       "26     0.882248  0.002672  0.011781  0.018127  0.085172\n",
       "27     0.147936  0.012530  0.097120  0.220490  0.521924\n",
       "28     0.457713  0.003026  0.030912  0.260471  0.247877\n",
       "29     0.421771  0.002376  0.023715  0.215344  0.336794\n",
       "...         ...       ...       ...       ...       ...\n",
       "11426  0.406091  0.001963  0.036373  0.364730  0.190844\n",
       "11427  0.168902  0.010389  0.123212  0.148640  0.548857\n",
       "11428  0.462325  0.001742  0.031224  0.299244  0.205465\n",
       "11429  0.535222  0.002486  0.026412  0.239839  0.196041\n",
       "11430  0.882248  0.002672  0.011781  0.018127  0.085172\n",
       "11431  0.042880  0.039041  0.104032  0.053685  0.760362\n",
       "11432  0.438017  0.001418  0.034434  0.354131  0.172000\n",
       "11433  0.178236  0.029349  0.082377  0.029604  0.680433\n",
       "11434  0.443512  0.001600  0.034866  0.349609  0.170413\n",
       "11435  0.038282  0.040905  0.111561  0.053421  0.755830\n",
       "11436  0.548208  0.007093  0.049103  0.092929  0.302667\n",
       "11437  0.039347  0.005061  0.107058  0.226095  0.622439\n",
       "11438  0.796977  0.004170  0.022986  0.028597  0.147270\n",
       "11439  0.522322  0.001472  0.025776  0.266217  0.184213\n",
       "11440  0.013350  0.029081  0.075722  0.003052  0.878795\n",
       "11441  0.407275  0.002168  0.027506  0.375173  0.187878\n",
       "11442  0.501947  0.001687  0.028223  0.256279  0.211864\n",
       "11443  0.591907  0.006313  0.046531  0.088062  0.267187\n",
       "11444  0.049677  0.031380  0.084849  0.037665  0.796429\n",
       "11445  0.043054  0.031318  0.092231  0.038532  0.794865\n",
       "11446  0.809111  0.002792  0.012310  0.018941  0.156845\n",
       "11447  0.560589  0.001864  0.026695  0.220976  0.189877\n",
       "11448  0.827818  0.001475  0.011054  0.081263  0.078390\n",
       "11449  0.443387  0.001881  0.034856  0.349511  0.170365\n",
       "11450  0.510270  0.001475  0.027685  0.260665  0.199903\n",
       "11451  0.809111  0.002792  0.012310  0.018941  0.156845\n",
       "11452  0.050970  0.027387  0.076868  0.027624  0.817152\n",
       "11453  0.050970  0.028996  0.084007  0.033995  0.802032\n",
       "11454  0.415845  0.002692  0.037247  0.336793  0.207423\n",
       "11455  0.029965  0.018077  0.087322  0.284326  0.580309\n",
       "\n",
       "[11456 rows x 5 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(ypred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
