{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_encode_dataset(dataset):\n",
    "    for column in dataset.columns.values:\n",
    "        dataset[column] = dataset[column].astype(str)\n",
    "        le.fit(y=dataset[column])\n",
    "        dataset[column] = le.transform(dataset[column])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MatthewBarnette/shelter_animals/.direnv/python-3.5.0/lib/python3.5/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/Users/MatthewBarnette/shelter_animals/.direnv/python-3.5.0/lib/python3.5/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#import the data I need\n",
    "test_data = pd.read_csv('csv_files/test.csv')\n",
    "animal_data = pd.read_csv('csv_files/train.csv')\n",
    "\n",
    "#Drop columns that I don't need\n",
    "animal_data = animal_data.drop(labels=['AnimalID', 'Name', 'DateTime', 'OutcomeSubtype'], axis=1)\n",
    "\n",
    "#setting up the test data\n",
    "test_index = test_data.ID\n",
    "test_data = test_data.drop(labels=['ID', 'Name', 'DateTime'], axis=1)\n",
    "test_data = label_encode_dataset(test_data)\n",
    "\n",
    "#splitting up the training data so I can use it to test how well my predictions are coming along\n",
    "train_animal_data, test_animal_data = train_test_split(animal_data, test_size= .25, random_state=53)\n",
    "\n",
    "#since the evaluation for this kaggle competition will be in multi-class logloss I've popped the outcomes off of the\n",
    "#dataset and changed the results into dummy variables\n",
    "outcome_train_animal_data = train_animal_data.pop('OutcomeType')\n",
    "le.fit(outcome_train_animal_data)\n",
    "outcome_train_animal_data = le.transform(outcome_train_animal_data)\n",
    "\n",
    "#repeat for the test data\n",
    "outcome_test_animal_data = test_animal_data.pop('OutcomeType')\n",
    "le.fit(outcome_test_animal_data)\n",
    "outcome_test_animal_data = le.transform(outcome_test_animal_data)\n",
    "\n",
    "train_animal_data = label_encode_dataset(train_animal_data)\n",
    "test_animal_data = label_encode_dataset(test_animal_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(train_animal_data, label=outcome_train_animal_data)\n",
    "dtest = xgb.DMatrix(test_animal_data, label=outcome_test_animal_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parm = {'bst:max_depth':1, 'bst:eta':.1, 'silent':5, 'objective':'multi:softprob', 'num_class':5, 'max_delta_step':8}\n",
    "parm['nthread'] = 10\n",
    "parm['eval_metric'] = 'mlogloss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evallist = [(dtrain,'train'), (dtest,'eval')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until eval error hasn't decreased in 3 rounds.\n",
      "[0]\ttrain-mlogloss:1.541485\teval-mlogloss:1.542814\n",
      "[1]\ttrain-mlogloss:1.484621\teval-mlogloss:1.486820\n",
      "[2]\ttrain-mlogloss:1.435884\teval-mlogloss:1.439115\n",
      "[3]\ttrain-mlogloss:1.393712\teval-mlogloss:1.397406\n",
      "[4]\ttrain-mlogloss:1.356622\teval-mlogloss:1.361093\n",
      "[5]\ttrain-mlogloss:1.323951\teval-mlogloss:1.329154\n",
      "[6]\ttrain-mlogloss:1.295218\teval-mlogloss:1.300867\n",
      "[7]\ttrain-mlogloss:1.269649\teval-mlogloss:1.275866\n",
      "[8]\ttrain-mlogloss:1.246802\teval-mlogloss:1.253438\n",
      "[9]\ttrain-mlogloss:1.226371\teval-mlogloss:1.233467\n",
      "[10]\ttrain-mlogloss:1.207724\teval-mlogloss:1.215178\n",
      "[11]\ttrain-mlogloss:1.191138\teval-mlogloss:1.198808\n",
      "[12]\ttrain-mlogloss:1.175664\teval-mlogloss:1.183908\n",
      "[13]\ttrain-mlogloss:1.162032\teval-mlogloss:1.170411\n",
      "[14]\ttrain-mlogloss:1.149248\teval-mlogloss:1.158058\n",
      "[15]\ttrain-mlogloss:1.137991\teval-mlogloss:1.146963\n",
      "[16]\ttrain-mlogloss:1.127539\teval-mlogloss:1.136628\n",
      "[17]\ttrain-mlogloss:1.117904\teval-mlogloss:1.127468\n",
      "[18]\ttrain-mlogloss:1.109164\teval-mlogloss:1.118936\n",
      "[19]\ttrain-mlogloss:1.101125\teval-mlogloss:1.111193\n",
      "[20]\ttrain-mlogloss:1.093843\teval-mlogloss:1.104057\n",
      "[21]\ttrain-mlogloss:1.087053\teval-mlogloss:1.097420\n",
      "[22]\ttrain-mlogloss:1.080674\teval-mlogloss:1.091286\n",
      "[23]\ttrain-mlogloss:1.074827\teval-mlogloss:1.085669\n",
      "[24]\ttrain-mlogloss:1.069364\teval-mlogloss:1.080568\n",
      "[25]\ttrain-mlogloss:1.064394\teval-mlogloss:1.075653\n",
      "[26]\ttrain-mlogloss:1.059673\teval-mlogloss:1.071513\n",
      "[27]\ttrain-mlogloss:1.055264\teval-mlogloss:1.067258\n",
      "[28]\ttrain-mlogloss:1.051202\teval-mlogloss:1.063412\n",
      "[29]\ttrain-mlogloss:1.047385\teval-mlogloss:1.059975\n",
      "[30]\ttrain-mlogloss:1.043824\teval-mlogloss:1.056476\n",
      "[31]\ttrain-mlogloss:1.040475\teval-mlogloss:1.053607\n",
      "[32]\ttrain-mlogloss:1.037306\teval-mlogloss:1.050684\n",
      "[33]\ttrain-mlogloss:1.034352\teval-mlogloss:1.047762\n",
      "[34]\ttrain-mlogloss:1.031610\teval-mlogloss:1.045302\n",
      "[35]\ttrain-mlogloss:1.028984\teval-mlogloss:1.042859\n",
      "[36]\ttrain-mlogloss:1.026515\teval-mlogloss:1.040706\n",
      "[37]\ttrain-mlogloss:1.024213\teval-mlogloss:1.038480\n",
      "[38]\ttrain-mlogloss:1.022054\teval-mlogloss:1.036632\n",
      "[39]\ttrain-mlogloss:1.019984\teval-mlogloss:1.034581\n",
      "[40]\ttrain-mlogloss:1.018021\teval-mlogloss:1.032815\n",
      "[41]\ttrain-mlogloss:1.016172\teval-mlogloss:1.031190\n",
      "[42]\ttrain-mlogloss:1.014415\teval-mlogloss:1.029512\n",
      "[43]\ttrain-mlogloss:1.012732\teval-mlogloss:1.027979\n",
      "[44]\ttrain-mlogloss:1.011164\teval-mlogloss:1.026639\n",
      "[45]\ttrain-mlogloss:1.009718\teval-mlogloss:1.025233\n",
      "[46]\ttrain-mlogloss:1.008291\teval-mlogloss:1.023972\n",
      "[47]\ttrain-mlogloss:1.006915\teval-mlogloss:1.022827\n",
      "[48]\ttrain-mlogloss:1.005682\teval-mlogloss:1.021669\n",
      "[49]\ttrain-mlogloss:1.004406\teval-mlogloss:1.020558\n",
      "[50]\ttrain-mlogloss:1.003261\teval-mlogloss:1.019639\n",
      "[51]\ttrain-mlogloss:1.002121\teval-mlogloss:1.018716\n",
      "[52]\ttrain-mlogloss:1.001072\teval-mlogloss:1.017796\n",
      "[53]\ttrain-mlogloss:1.000019\teval-mlogloss:1.016779\n",
      "[54]\ttrain-mlogloss:0.999027\teval-mlogloss:1.015976\n",
      "[55]\ttrain-mlogloss:0.998057\teval-mlogloss:1.015215\n",
      "[56]\ttrain-mlogloss:0.997140\teval-mlogloss:1.014531\n",
      "[57]\ttrain-mlogloss:0.996249\teval-mlogloss:1.013701\n",
      "[58]\ttrain-mlogloss:0.995365\teval-mlogloss:1.012855\n",
      "[59]\ttrain-mlogloss:0.994553\teval-mlogloss:1.012244\n",
      "[60]\ttrain-mlogloss:0.993711\teval-mlogloss:1.011481\n",
      "[61]\ttrain-mlogloss:0.992931\teval-mlogloss:1.010850\n",
      "[62]\ttrain-mlogloss:0.992140\teval-mlogloss:1.010249\n",
      "[63]\ttrain-mlogloss:0.991411\teval-mlogloss:1.009600\n",
      "[64]\ttrain-mlogloss:0.990663\teval-mlogloss:1.008880\n",
      "[65]\ttrain-mlogloss:0.989981\teval-mlogloss:1.008366\n",
      "[66]\ttrain-mlogloss:0.989295\teval-mlogloss:1.007696\n",
      "[67]\ttrain-mlogloss:0.988608\teval-mlogloss:1.007183\n",
      "[68]\ttrain-mlogloss:0.987988\teval-mlogloss:1.006726\n",
      "[69]\ttrain-mlogloss:0.987341\teval-mlogloss:1.006091\n",
      "[70]\ttrain-mlogloss:0.986723\teval-mlogloss:1.005442\n",
      "[71]\ttrain-mlogloss:0.986135\teval-mlogloss:1.005038\n",
      "[72]\ttrain-mlogloss:0.985539\teval-mlogloss:1.004477\n",
      "[73]\ttrain-mlogloss:0.984941\teval-mlogloss:1.004035\n",
      "[74]\ttrain-mlogloss:0.984389\teval-mlogloss:1.003476\n",
      "[75]\ttrain-mlogloss:0.983865\teval-mlogloss:1.003004\n",
      "[76]\ttrain-mlogloss:0.983307\teval-mlogloss:1.002533\n",
      "[77]\ttrain-mlogloss:0.982809\teval-mlogloss:1.002099\n",
      "[78]\ttrain-mlogloss:0.982280\teval-mlogloss:1.001572\n",
      "[79]\ttrain-mlogloss:0.981767\teval-mlogloss:1.001156\n",
      "[80]\ttrain-mlogloss:0.981262\teval-mlogloss:1.000807\n",
      "[81]\ttrain-mlogloss:0.980820\teval-mlogloss:1.000372\n",
      "[82]\ttrain-mlogloss:0.980320\teval-mlogloss:0.999897\n",
      "[83]\ttrain-mlogloss:0.979864\teval-mlogloss:0.999437\n",
      "[84]\ttrain-mlogloss:0.979411\teval-mlogloss:0.999088\n",
      "[85]\ttrain-mlogloss:0.978924\teval-mlogloss:0.998689\n",
      "[86]\ttrain-mlogloss:0.978511\teval-mlogloss:0.998313\n",
      "[87]\ttrain-mlogloss:0.978058\teval-mlogloss:0.997981\n",
      "[88]\ttrain-mlogloss:0.977625\teval-mlogloss:0.997570\n",
      "[89]\ttrain-mlogloss:0.977187\teval-mlogloss:0.997071\n",
      "[90]\ttrain-mlogloss:0.976800\teval-mlogloss:0.996805\n",
      "[91]\ttrain-mlogloss:0.976347\teval-mlogloss:0.996465\n",
      "[92]\ttrain-mlogloss:0.975990\teval-mlogloss:0.996081\n",
      "[93]\ttrain-mlogloss:0.975570\teval-mlogloss:0.995708\n",
      "[94]\ttrain-mlogloss:0.975199\teval-mlogloss:0.995392\n",
      "[95]\ttrain-mlogloss:0.974824\teval-mlogloss:0.995014\n",
      "[96]\ttrain-mlogloss:0.974407\teval-mlogloss:0.994634\n",
      "[97]\ttrain-mlogloss:0.974057\teval-mlogloss:0.994295\n",
      "[98]\ttrain-mlogloss:0.973684\teval-mlogloss:0.994076\n",
      "[99]\ttrain-mlogloss:0.973303\teval-mlogloss:0.993767\n",
      "[100]\ttrain-mlogloss:0.972973\teval-mlogloss:0.993419\n",
      "[101]\ttrain-mlogloss:0.972614\teval-mlogloss:0.992976\n",
      "[102]\ttrain-mlogloss:0.972269\teval-mlogloss:0.992680\n",
      "[103]\ttrain-mlogloss:0.971925\teval-mlogloss:0.992469\n",
      "[104]\ttrain-mlogloss:0.971596\teval-mlogloss:0.992338\n",
      "[105]\ttrain-mlogloss:0.971240\teval-mlogloss:0.992052\n",
      "[106]\ttrain-mlogloss:0.970905\teval-mlogloss:0.991672\n",
      "[107]\ttrain-mlogloss:0.970591\teval-mlogloss:0.991475\n",
      "[108]\ttrain-mlogloss:0.970268\teval-mlogloss:0.991135\n",
      "[109]\ttrain-mlogloss:0.969951\teval-mlogloss:0.990848\n",
      "[110]\ttrain-mlogloss:0.969638\teval-mlogloss:0.990522\n",
      "[111]\ttrain-mlogloss:0.969319\teval-mlogloss:0.990203\n",
      "[112]\ttrain-mlogloss:0.969032\teval-mlogloss:0.989930\n",
      "[113]\ttrain-mlogloss:0.968716\teval-mlogloss:0.989565\n",
      "[114]\ttrain-mlogloss:0.968419\teval-mlogloss:0.989353\n",
      "[115]\ttrain-mlogloss:0.968131\teval-mlogloss:0.989050\n",
      "[116]\ttrain-mlogloss:0.967815\teval-mlogloss:0.988788\n",
      "[117]\ttrain-mlogloss:0.967512\teval-mlogloss:0.988561\n",
      "[118]\ttrain-mlogloss:0.967243\teval-mlogloss:0.988287\n",
      "[119]\ttrain-mlogloss:0.966952\teval-mlogloss:0.988018\n",
      "[120]\ttrain-mlogloss:0.966666\teval-mlogloss:0.987776\n",
      "[121]\ttrain-mlogloss:0.966383\teval-mlogloss:0.987435\n",
      "[122]\ttrain-mlogloss:0.966118\teval-mlogloss:0.987267\n",
      "[123]\ttrain-mlogloss:0.965835\teval-mlogloss:0.987011\n",
      "[124]\ttrain-mlogloss:0.965576\teval-mlogloss:0.986871\n",
      "[125]\ttrain-mlogloss:0.965317\teval-mlogloss:0.986646\n",
      "[126]\ttrain-mlogloss:0.965025\teval-mlogloss:0.986315\n",
      "[127]\ttrain-mlogloss:0.964778\teval-mlogloss:0.986071\n",
      "[128]\ttrain-mlogloss:0.964510\teval-mlogloss:0.985789\n",
      "[129]\ttrain-mlogloss:0.964258\teval-mlogloss:0.985593\n",
      "[130]\ttrain-mlogloss:0.964005\teval-mlogloss:0.985366\n",
      "[131]\ttrain-mlogloss:0.963751\teval-mlogloss:0.985141\n",
      "[132]\ttrain-mlogloss:0.963498\teval-mlogloss:0.984892\n",
      "[133]\ttrain-mlogloss:0.963248\teval-mlogloss:0.984691\n",
      "[134]\ttrain-mlogloss:0.963008\teval-mlogloss:0.984499\n",
      "[135]\ttrain-mlogloss:0.962755\teval-mlogloss:0.984346\n",
      "[136]\ttrain-mlogloss:0.962538\teval-mlogloss:0.984147\n",
      "[137]\ttrain-mlogloss:0.962288\teval-mlogloss:0.983908\n",
      "[138]\ttrain-mlogloss:0.962062\teval-mlogloss:0.983624\n",
      "[139]\ttrain-mlogloss:0.961815\teval-mlogloss:0.983472\n",
      "[140]\ttrain-mlogloss:0.961588\teval-mlogloss:0.983123\n",
      "[141]\ttrain-mlogloss:0.961348\teval-mlogloss:0.982983\n",
      "[142]\ttrain-mlogloss:0.961128\teval-mlogloss:0.982834\n",
      "[143]\ttrain-mlogloss:0.960890\teval-mlogloss:0.982628\n",
      "[144]\ttrain-mlogloss:0.960677\teval-mlogloss:0.982402\n",
      "[145]\ttrain-mlogloss:0.960470\teval-mlogloss:0.982259\n",
      "[146]\ttrain-mlogloss:0.960224\teval-mlogloss:0.981974\n",
      "[147]\ttrain-mlogloss:0.960017\teval-mlogloss:0.981757\n",
      "[148]\ttrain-mlogloss:0.959800\teval-mlogloss:0.981593\n",
      "[149]\ttrain-mlogloss:0.959590\teval-mlogloss:0.981398\n",
      "[150]\ttrain-mlogloss:0.959361\teval-mlogloss:0.981122\n",
      "[151]\ttrain-mlogloss:0.959148\teval-mlogloss:0.980992\n",
      "[152]\ttrain-mlogloss:0.958952\teval-mlogloss:0.980698\n",
      "[153]\ttrain-mlogloss:0.958724\teval-mlogloss:0.980561\n",
      "[154]\ttrain-mlogloss:0.958525\teval-mlogloss:0.980478\n",
      "[155]\ttrain-mlogloss:0.958331\teval-mlogloss:0.980353\n",
      "[156]\ttrain-mlogloss:0.958124\teval-mlogloss:0.980123\n",
      "[157]\ttrain-mlogloss:0.957901\teval-mlogloss:0.980016\n",
      "[158]\ttrain-mlogloss:0.957730\teval-mlogloss:0.979750\n",
      "[159]\ttrain-mlogloss:0.957513\teval-mlogloss:0.979595\n",
      "[160]\ttrain-mlogloss:0.957320\teval-mlogloss:0.979294\n",
      "[161]\ttrain-mlogloss:0.957114\teval-mlogloss:0.979188\n",
      "[162]\ttrain-mlogloss:0.956924\teval-mlogloss:0.978995\n",
      "[163]\ttrain-mlogloss:0.956728\teval-mlogloss:0.978848\n",
      "[164]\ttrain-mlogloss:0.956542\teval-mlogloss:0.978748\n",
      "[165]\ttrain-mlogloss:0.956361\teval-mlogloss:0.978536\n",
      "[166]\ttrain-mlogloss:0.956155\teval-mlogloss:0.978385\n",
      "[167]\ttrain-mlogloss:0.955976\teval-mlogloss:0.978135\n",
      "[168]\ttrain-mlogloss:0.955789\teval-mlogloss:0.977946\n",
      "[169]\ttrain-mlogloss:0.955598\teval-mlogloss:0.977690\n",
      "[170]\ttrain-mlogloss:0.955420\teval-mlogloss:0.977589\n",
      "[171]\ttrain-mlogloss:0.955251\teval-mlogloss:0.977377\n",
      "[172]\ttrain-mlogloss:0.955057\teval-mlogloss:0.977244\n",
      "[173]\ttrain-mlogloss:0.954869\teval-mlogloss:0.977149\n",
      "[174]\ttrain-mlogloss:0.954696\teval-mlogloss:0.976975\n",
      "[175]\ttrain-mlogloss:0.954512\teval-mlogloss:0.976842\n",
      "[176]\ttrain-mlogloss:0.954345\teval-mlogloss:0.976771\n",
      "[177]\ttrain-mlogloss:0.954168\teval-mlogloss:0.976631\n",
      "[178]\ttrain-mlogloss:0.954004\teval-mlogloss:0.976409\n",
      "[179]\ttrain-mlogloss:0.953820\teval-mlogloss:0.976312\n",
      "[180]\ttrain-mlogloss:0.953644\teval-mlogloss:0.976146\n",
      "[181]\ttrain-mlogloss:0.953474\teval-mlogloss:0.976106\n",
      "[182]\ttrain-mlogloss:0.953309\teval-mlogloss:0.975894\n",
      "[183]\ttrain-mlogloss:0.953136\teval-mlogloss:0.975760\n",
      "[184]\ttrain-mlogloss:0.952986\teval-mlogloss:0.975576\n",
      "[185]\ttrain-mlogloss:0.952823\teval-mlogloss:0.975456\n",
      "[186]\ttrain-mlogloss:0.952650\teval-mlogloss:0.975364\n",
      "[187]\ttrain-mlogloss:0.952492\teval-mlogloss:0.975107\n",
      "[188]\ttrain-mlogloss:0.952324\teval-mlogloss:0.974968\n",
      "[189]\ttrain-mlogloss:0.952160\teval-mlogloss:0.974797\n",
      "[190]\ttrain-mlogloss:0.951998\teval-mlogloss:0.974684\n",
      "[191]\ttrain-mlogloss:0.951849\teval-mlogloss:0.974534\n",
      "[192]\ttrain-mlogloss:0.951680\teval-mlogloss:0.974464\n",
      "[193]\ttrain-mlogloss:0.951530\teval-mlogloss:0.974265\n",
      "[194]\ttrain-mlogloss:0.951368\teval-mlogloss:0.974230\n",
      "[195]\ttrain-mlogloss:0.951213\teval-mlogloss:0.974043\n",
      "[196]\ttrain-mlogloss:0.951058\teval-mlogloss:0.973937\n",
      "[197]\ttrain-mlogloss:0.950905\teval-mlogloss:0.973785\n",
      "[198]\ttrain-mlogloss:0.950761\teval-mlogloss:0.973681\n",
      "[199]\ttrain-mlogloss:0.950610\teval-mlogloss:0.973568\n",
      "[200]\ttrain-mlogloss:0.950452\teval-mlogloss:0.973549\n",
      "[201]\ttrain-mlogloss:0.950307\teval-mlogloss:0.973467\n",
      "[202]\ttrain-mlogloss:0.950152\teval-mlogloss:0.973429\n",
      "[203]\ttrain-mlogloss:0.950010\teval-mlogloss:0.973313\n",
      "[204]\ttrain-mlogloss:0.949863\teval-mlogloss:0.973155\n",
      "[205]\ttrain-mlogloss:0.949718\teval-mlogloss:0.973048\n",
      "[206]\ttrain-mlogloss:0.949583\teval-mlogloss:0.972882\n",
      "[207]\ttrain-mlogloss:0.949433\teval-mlogloss:0.972797\n",
      "[208]\ttrain-mlogloss:0.949292\teval-mlogloss:0.972710\n",
      "[209]\ttrain-mlogloss:0.949154\teval-mlogloss:0.972636\n",
      "[210]\ttrain-mlogloss:0.948997\teval-mlogloss:0.972465\n",
      "[211]\ttrain-mlogloss:0.948862\teval-mlogloss:0.972394\n",
      "[212]\ttrain-mlogloss:0.948719\teval-mlogloss:0.972242\n",
      "[213]\ttrain-mlogloss:0.948591\teval-mlogloss:0.972164\n",
      "[214]\ttrain-mlogloss:0.948442\teval-mlogloss:0.971981\n",
      "[215]\ttrain-mlogloss:0.948309\teval-mlogloss:0.971899\n",
      "[216]\ttrain-mlogloss:0.948176\teval-mlogloss:0.971727\n",
      "[217]\ttrain-mlogloss:0.948044\teval-mlogloss:0.971656\n",
      "[218]\ttrain-mlogloss:0.947910\teval-mlogloss:0.971565\n",
      "[219]\ttrain-mlogloss:0.947770\teval-mlogloss:0.971485\n",
      "[220]\ttrain-mlogloss:0.947635\teval-mlogloss:0.971406\n",
      "[221]\ttrain-mlogloss:0.947520\teval-mlogloss:0.971328\n",
      "[222]\ttrain-mlogloss:0.947377\teval-mlogloss:0.971222\n",
      "[223]\ttrain-mlogloss:0.947250\teval-mlogloss:0.971110\n",
      "[224]\ttrain-mlogloss:0.947118\teval-mlogloss:0.970961\n",
      "[225]\ttrain-mlogloss:0.946984\teval-mlogloss:0.970888\n",
      "[226]\ttrain-mlogloss:0.946864\teval-mlogloss:0.970718\n",
      "[227]\ttrain-mlogloss:0.946728\teval-mlogloss:0.970696\n",
      "[228]\ttrain-mlogloss:0.946597\teval-mlogloss:0.970557\n",
      "[229]\ttrain-mlogloss:0.946471\teval-mlogloss:0.970466\n",
      "[230]\ttrain-mlogloss:0.946352\teval-mlogloss:0.970377\n",
      "[231]\ttrain-mlogloss:0.946233\teval-mlogloss:0.970325\n",
      "[232]\ttrain-mlogloss:0.946115\teval-mlogloss:0.970281\n",
      "[233]\ttrain-mlogloss:0.945996\teval-mlogloss:0.970140\n",
      "[234]\ttrain-mlogloss:0.945860\teval-mlogloss:0.970123\n",
      "[235]\ttrain-mlogloss:0.945737\teval-mlogloss:0.970023\n",
      "[236]\ttrain-mlogloss:0.945621\teval-mlogloss:0.969958\n",
      "[237]\ttrain-mlogloss:0.945495\teval-mlogloss:0.969896\n",
      "[238]\ttrain-mlogloss:0.945388\teval-mlogloss:0.969832\n",
      "[239]\ttrain-mlogloss:0.945254\teval-mlogloss:0.969691\n",
      "[240]\ttrain-mlogloss:0.945133\teval-mlogloss:0.969675\n",
      "[241]\ttrain-mlogloss:0.945020\teval-mlogloss:0.969554\n",
      "[242]\ttrain-mlogloss:0.944911\teval-mlogloss:0.969490\n",
      "[243]\ttrain-mlogloss:0.944784\teval-mlogloss:0.969358\n",
      "[244]\ttrain-mlogloss:0.944673\teval-mlogloss:0.969271\n",
      "[245]\ttrain-mlogloss:0.944555\teval-mlogloss:0.969159\n",
      "[246]\ttrain-mlogloss:0.944444\teval-mlogloss:0.969080\n",
      "[247]\ttrain-mlogloss:0.944322\teval-mlogloss:0.968928\n",
      "[248]\ttrain-mlogloss:0.944216\teval-mlogloss:0.968916\n",
      "[249]\ttrain-mlogloss:0.944103\teval-mlogloss:0.968868\n",
      "[250]\ttrain-mlogloss:0.943996\teval-mlogloss:0.968833\n",
      "[251]\ttrain-mlogloss:0.943889\teval-mlogloss:0.968758\n",
      "[252]\ttrain-mlogloss:0.943768\teval-mlogloss:0.968683\n",
      "[253]\ttrain-mlogloss:0.943665\teval-mlogloss:0.968594\n",
      "[254]\ttrain-mlogloss:0.943547\teval-mlogloss:0.968504\n",
      "[255]\ttrain-mlogloss:0.943438\teval-mlogloss:0.968365\n",
      "[256]\ttrain-mlogloss:0.943326\teval-mlogloss:0.968306\n",
      "[257]\ttrain-mlogloss:0.943218\teval-mlogloss:0.968195\n",
      "[258]\ttrain-mlogloss:0.943113\teval-mlogloss:0.968146\n",
      "[259]\ttrain-mlogloss:0.943015\teval-mlogloss:0.968046\n",
      "[260]\ttrain-mlogloss:0.942906\teval-mlogloss:0.968009\n",
      "[261]\ttrain-mlogloss:0.942802\teval-mlogloss:0.967876\n",
      "[262]\ttrain-mlogloss:0.942688\teval-mlogloss:0.967826\n",
      "[263]\ttrain-mlogloss:0.942583\teval-mlogloss:0.967676\n",
      "[264]\ttrain-mlogloss:0.942481\teval-mlogloss:0.967664\n",
      "[265]\ttrain-mlogloss:0.942381\teval-mlogloss:0.967620\n",
      "[266]\ttrain-mlogloss:0.942281\teval-mlogloss:0.967553\n",
      "[267]\ttrain-mlogloss:0.942182\teval-mlogloss:0.967493\n",
      "[268]\ttrain-mlogloss:0.942075\teval-mlogloss:0.967447\n",
      "[269]\ttrain-mlogloss:0.941961\teval-mlogloss:0.967307\n",
      "[270]\ttrain-mlogloss:0.941862\teval-mlogloss:0.967298\n",
      "[271]\ttrain-mlogloss:0.941774\teval-mlogloss:0.967262\n",
      "[272]\ttrain-mlogloss:0.941674\teval-mlogloss:0.967155\n",
      "[273]\ttrain-mlogloss:0.941572\teval-mlogloss:0.967182\n",
      "[274]\ttrain-mlogloss:0.941481\teval-mlogloss:0.967038\n",
      "[275]\ttrain-mlogloss:0.941370\teval-mlogloss:0.966988\n",
      "[276]\ttrain-mlogloss:0.941278\teval-mlogloss:0.966865\n",
      "[277]\ttrain-mlogloss:0.941180\teval-mlogloss:0.966816\n",
      "[278]\ttrain-mlogloss:0.941080\teval-mlogloss:0.966794\n",
      "[279]\ttrain-mlogloss:0.940983\teval-mlogloss:0.966700\n",
      "[280]\ttrain-mlogloss:0.940891\teval-mlogloss:0.966634\n",
      "[281]\ttrain-mlogloss:0.940795\teval-mlogloss:0.966578\n",
      "[282]\ttrain-mlogloss:0.940697\teval-mlogloss:0.966527\n",
      "[283]\ttrain-mlogloss:0.940610\teval-mlogloss:0.966469\n",
      "[284]\ttrain-mlogloss:0.940512\teval-mlogloss:0.966483\n",
      "[285]\ttrain-mlogloss:0.940425\teval-mlogloss:0.966370\n",
      "[286]\ttrain-mlogloss:0.940322\teval-mlogloss:0.966292\n",
      "[287]\ttrain-mlogloss:0.940235\teval-mlogloss:0.966223\n",
      "[288]\ttrain-mlogloss:0.940139\teval-mlogloss:0.966109\n",
      "[289]\ttrain-mlogloss:0.940040\teval-mlogloss:0.966156\n",
      "[290]\ttrain-mlogloss:0.939956\teval-mlogloss:0.966028\n",
      "[291]\ttrain-mlogloss:0.939868\teval-mlogloss:0.966021\n",
      "[292]\ttrain-mlogloss:0.939777\teval-mlogloss:0.965906\n",
      "[293]\ttrain-mlogloss:0.939684\teval-mlogloss:0.965851\n",
      "[294]\ttrain-mlogloss:0.939598\teval-mlogloss:0.965832\n",
      "[295]\ttrain-mlogloss:0.939506\teval-mlogloss:0.965814\n",
      "[296]\ttrain-mlogloss:0.939421\teval-mlogloss:0.965829\n",
      "[297]\ttrain-mlogloss:0.939338\teval-mlogloss:0.965711\n",
      "[298]\ttrain-mlogloss:0.939246\teval-mlogloss:0.965710\n",
      "[299]\ttrain-mlogloss:0.939148\teval-mlogloss:0.965569\n",
      "[300]\ttrain-mlogloss:0.939067\teval-mlogloss:0.965523\n",
      "[301]\ttrain-mlogloss:0.938977\teval-mlogloss:0.965414\n",
      "[302]\ttrain-mlogloss:0.938903\teval-mlogloss:0.965383\n",
      "[303]\ttrain-mlogloss:0.938808\teval-mlogloss:0.965283\n",
      "[304]\ttrain-mlogloss:0.938728\teval-mlogloss:0.965249\n",
      "[305]\ttrain-mlogloss:0.938639\teval-mlogloss:0.965153\n",
      "[306]\ttrain-mlogloss:0.938560\teval-mlogloss:0.965112\n",
      "[307]\ttrain-mlogloss:0.938471\teval-mlogloss:0.965069\n",
      "[308]\ttrain-mlogloss:0.938380\teval-mlogloss:0.965087\n",
      "[309]\ttrain-mlogloss:0.938310\teval-mlogloss:0.965060\n",
      "[310]\ttrain-mlogloss:0.938221\teval-mlogloss:0.964941\n",
      "[311]\ttrain-mlogloss:0.938149\teval-mlogloss:0.964912\n",
      "[312]\ttrain-mlogloss:0.938064\teval-mlogloss:0.964827\n",
      "[313]\ttrain-mlogloss:0.937983\teval-mlogloss:0.964784\n",
      "[314]\ttrain-mlogloss:0.937903\teval-mlogloss:0.964745\n",
      "[315]\ttrain-mlogloss:0.937822\teval-mlogloss:0.964733\n",
      "[316]\ttrain-mlogloss:0.937734\teval-mlogloss:0.964671\n",
      "[317]\ttrain-mlogloss:0.937656\teval-mlogloss:0.964706\n",
      "[318]\ttrain-mlogloss:0.937581\teval-mlogloss:0.964635\n",
      "[319]\ttrain-mlogloss:0.937503\teval-mlogloss:0.964590\n",
      "[320]\ttrain-mlogloss:0.937418\teval-mlogloss:0.964484\n",
      "[321]\ttrain-mlogloss:0.937336\teval-mlogloss:0.964409\n",
      "[322]\ttrain-mlogloss:0.937262\teval-mlogloss:0.964384\n",
      "[323]\ttrain-mlogloss:0.937181\teval-mlogloss:0.964345\n",
      "[324]\ttrain-mlogloss:0.937110\teval-mlogloss:0.964284\n",
      "[325]\ttrain-mlogloss:0.937031\teval-mlogloss:0.964265\n",
      "[326]\ttrain-mlogloss:0.936953\teval-mlogloss:0.964206\n",
      "[327]\ttrain-mlogloss:0.936886\teval-mlogloss:0.964154\n",
      "[328]\ttrain-mlogloss:0.936804\teval-mlogloss:0.964106\n",
      "[329]\ttrain-mlogloss:0.936731\teval-mlogloss:0.964056\n",
      "[330]\ttrain-mlogloss:0.936647\teval-mlogloss:0.963973\n",
      "[331]\ttrain-mlogloss:0.936580\teval-mlogloss:0.963930\n",
      "[332]\ttrain-mlogloss:0.936501\teval-mlogloss:0.963886\n",
      "[333]\ttrain-mlogloss:0.936423\teval-mlogloss:0.963922\n",
      "[334]\ttrain-mlogloss:0.936351\teval-mlogloss:0.963874\n",
      "[335]\ttrain-mlogloss:0.936286\teval-mlogloss:0.963785\n",
      "[336]\ttrain-mlogloss:0.936204\teval-mlogloss:0.963754\n",
      "[337]\ttrain-mlogloss:0.936124\teval-mlogloss:0.963688\n",
      "[338]\ttrain-mlogloss:0.936058\teval-mlogloss:0.963667\n",
      "[339]\ttrain-mlogloss:0.935996\teval-mlogloss:0.963639\n",
      "[340]\ttrain-mlogloss:0.935919\teval-mlogloss:0.963630\n",
      "[341]\ttrain-mlogloss:0.935852\teval-mlogloss:0.963573\n",
      "[342]\ttrain-mlogloss:0.935784\teval-mlogloss:0.963491\n",
      "[343]\ttrain-mlogloss:0.935701\teval-mlogloss:0.963428\n",
      "[344]\ttrain-mlogloss:0.935628\teval-mlogloss:0.963402\n",
      "[345]\ttrain-mlogloss:0.935574\teval-mlogloss:0.963422\n",
      "[346]\ttrain-mlogloss:0.935496\teval-mlogloss:0.963328\n",
      "[347]\ttrain-mlogloss:0.935421\teval-mlogloss:0.963348\n",
      "[348]\ttrain-mlogloss:0.935360\teval-mlogloss:0.963301\n",
      "[349]\ttrain-mlogloss:0.935287\teval-mlogloss:0.963341\n",
      "[350]\ttrain-mlogloss:0.935218\teval-mlogloss:0.963265\n",
      "[351]\ttrain-mlogloss:0.935148\teval-mlogloss:0.963295\n",
      "[352]\ttrain-mlogloss:0.935072\teval-mlogloss:0.963222\n",
      "[353]\ttrain-mlogloss:0.935015\teval-mlogloss:0.963347\n",
      "[354]\ttrain-mlogloss:0.934941\teval-mlogloss:0.963261\n",
      "[355]\ttrain-mlogloss:0.934876\teval-mlogloss:0.963317\n",
      "Stopping. Best iteration:\n",
      "[352]\ttrain-mlogloss:0.935072\teval-mlogloss:0.963222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_round = 1000\n",
    "bst = xgb.train(parm, dtrain, num_round, evallist, early_stopping_rounds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MatthewBarnette/shelter_animals/.direnv/python-3.5.0/lib/python3.5/site-packages/xgboost/core.py:840: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  preds = preds.reshape(nrow, preds.size / nrow)\n"
     ]
    }
   ],
   "source": [
    "dtest = xgb.DMatrix(test_data)\n",
    "ypred = bst.predict(dtest, output_margin=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ypred = pd.DataFrame(ypred)\n",
    "ypred = ypred.rename(columns={0: 'Adoption', 1:'Died', 2:'Euthanasia', 3:'Return_to_owner', 4:'Transfer'})\n",
    "ypred.index = test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ypred.to_csv('Predictions/XGBoost.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
